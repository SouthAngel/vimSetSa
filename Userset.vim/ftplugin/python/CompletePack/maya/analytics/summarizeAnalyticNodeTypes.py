"""
Summarize all of the analyticNodeType data into a pair of spreadsheets.
The optional parameter indicates the directory where the data is to
be found. If omitted it will assume the current directory.

If the file defaultNodes.csv exists then it will contain the list of
Maya's default (undeletable) nodes and should be in this form:

defaultNodes.csv
    "Default Node","Node Type"
    "DEFAULT NODE NAME","DEFAULT NODE TYPE"
    ...

All nodes appearing in this file will be filtered out of the analytics.
If the file doesn't exist then all nodes will be reported.

The directory is scanned for analytic collections. They appear as a
directory containing the file 'NodeTypes.csv'. All of those
files are scanned and then summarized into the following two files:

summaryNodeTypes.csv
    The first file contains a list of the merged contents of all node type
    analytic files, filtered to remove default nodes. Only node types with
    a count > 0 are considered. For files A, B, and C the output will look
    like this:

        FILEA,,,FILEB,,,FILEC,,,
        ,Node Type,Count,,Node Type,Count,,Node Type,Count
        ,BLAH,23,,FOO,42,,BAR,11

summaryNodeTypeCounts.csv
    This indicates there the most frequent node types are BLAH in FILEA
    with 23 instances, FOO in FILEB with 42 instance, and BAR in FILEC
    with 11 instances.

    The second file contains a list of the merged contents of all node type
    analytic files, filtered to remove default nodes, sorted and aligned into
    one row per node type for node types in any file. If the node type count
    in a particular file is 0 then the field will be left empty rather than

    populating with a '0' to make visual inspection easier.

    The format of the CSV file is something like this:

        Sorted By Node Type Count,,,Sorted By Appearances,,,,Sorted By Node Type
        Node Type,Count,,Node Type,Appearances,Count,,,Node Type,Totals,FILEA,FILEB,FILEC
        BAR,11933,,FOO,26,4201,,BLAH,125,75,,50

    This indicates that node type BAR is the most frequent with 11933
    nodes in all files, though FOO appears in the most files at 26 with
    a (smaller) total of 4201 instances in those files, and for node type
    BLAH there are 125 of them in FILEA, none of them in FILEB, and 50 of
    them in FILEC.  The rows are sorted by node type name, ascending
    alphabetically.
"""
import os
import csv
import sys
import getopt
import operator

# Name of the file to which the node types analytic dumped its results
# Format is CSV file with four columns containing the count information:
#    Node Type : Leaf type being counted (e.g. 'transform')
#    Depth     : How many levels deep this type is in the node hierarchy
#    Hierarchy : |-separated full node type hierarchy (e.g. 'transform|dagNode|entity|containerBase|TdependNode')
#    Count     : How many nodes of this exact type appeared in the file (including defaults)
ANALYTIC_FILENAME = 'NodeTypes.csv'

# Name of files where summarized results will be dumped
DETAILED_FILENAME = 'summaryNodeTypes.csv'
SUMMARY_FILENAME = 'summaryNodeTypeCounts.csv'

# Name of the file in which the list of default nodes is found
# Format is CSV file listing all default nodes and their type in two columns:
#    Default Node : Name of default node (e.g. "time1")
#    Node Type    : Leaf type of node (e.g. "time")
DEFAULT_NODE_FILENAME = 'defaultNodes.csv'

#======================================================================
#
class NodeTypeSummary(object):
    """
    Reads in the node type analytic results and summarizes them into
    a more comprehensible format.
    """
    def __init__(self, rootDir):
        """
        Create the object and initialize everything to be empty.

        rootDir : Topmost directory in which to look for analytics
        """
        self.directoriesToSummarize = []
        self.defaultCounts = {}
        self.rootDir = rootDir
        self.maxRowCount = 0
        self.nodeTypeData = {}
        self.nodeTypeTotals = {}
        self.nodeTypeCounts = {}
        self.nodeTypeCountTotals = {}
        self.nodeTypeAppearances = {}
        self.verbose = False

    #======================================================================
    #
    def __debug(self, msg):
        """
        Print a message if the verbose output mode is turned on
        """
        if self.verbose:
            print msg

    #======================================================================
    #
    def __findAnalyticDirectories(self):
        """
        Descend the rootDir and find all directories below it containing the set
        of files generated by running animation analytics. The key file it looks
        for is ANALYTIC_FILENAME. If it finds that it assumes the directory
        contains analytic information and processes it in order.
        """
        for root, _, files in os.walk(self.rootDir):
            for name in files:
                if name == ANALYTIC_FILENAME:
                    self.directoriesToSummarize.append( root )

        self.directoriesToSummarize.sort( key=lambda x: x.lower() )
        print 'Analyzing a total of %d directories' % len(self.directoriesToSummarize)

    #======================================================================
    #
    def __readDefaultNodes(self):
        """
        Read the list of default nodes so that they can be filtered out of the results.
        If there is a default node list it should exist at the root of the directory
        being analyzed.
        """
        defaultNodePath = os.path.join(self.rootDir, DEFAULT_NODE_FILENAME)
        try:
            self.defaultCounts = {}
            with open(defaultNodePath, 'r') as csvfile:
                defaultReader = csv.reader(csvfile)
                for row in defaultReader:
                    if row[0] == 'Default Node':
                        continue
                    self.defaultCounts[row[1]] = self.defaultCounts.get(row[1],0) + 1
            self.__debug( 'Using default list found at %s' % self.rootDir )
        except Exception,ex:
            print 'No defaults (%s), all nodes will be reported' % str(ex)

    #======================================================================
    #
    def __readAnalyticResults(self):
        """
        Walk the directories and read in the results from the analytic
        files located in those directories.
        """
        self.maxRowCount = 0
        self.nodeTypeData = {}
        self.nodeTypeTotals = {}
        self.nodeTypeCounts = {}
        self.nodeTypeCountTotals = {}
        self.nodeTypeAppearances = {}

        analyticsFound = 0
        for analyticDir in self.directoriesToSummarize:
            nodeTypeFile = os.path.join(analyticDir, ANALYTIC_FILENAME)
            self.__debug( 'Processing directory %s' % analyticDir )
            self.nodeTypeData[analyticDir] = []
            self.nodeTypeCounts[analyticDir] = {}

            if not os.path.isfile(nodeTypeFile):
                print 'ERR: Skipping directory %s, it has no analytics' % analyticDir
                continue

            analyticsFound += 1
            # Load the node type counts, keeping track of the maximum number of rows
            # for later formatting (since CSV files have to be written out by the row)
            with open(nodeTypeFile, 'r') as csvfile:
                nodeTypeReader = csv.reader(csvfile)
                myNodeTypeCounts = {}
                for row in nodeTypeReader:
                    if row[0] == 'Node Type':
                        assert (len(row) > 2 and row[3] == 'Count') or (row[1] == 'Count')
                        continue

                    if len(row) > 2:
                        count = int(row[3])
                    else:
                        # Old format from customers only had two columns
                        count = int(row[1])

                    # Remove the defaults from the counts. Assume that the default
                    # node list came from the same cut of Maya as the analytic results
                    # since we don't have the node name information for a true match.
                    if row[0] in self.defaultCounts:
                        count = count - self.defaultCounts[row[0]]
                    if count > 0:
                        myNodeTypeCounts[row[0]]  = count
                    if len(myNodeTypeCounts) > self.maxRowCount:
                        self.maxRowCount = len(myNodeTypeCounts)
            # Since we have to extract by index to accommodate writing rows the
            # dictionary has to be pulled out into two parallel lists.
            self.nodeTypeTotals[analyticDir] = 0
            for nodeType,count in sorted(myNodeTypeCounts.iteritems(), key=operator.itemgetter(1), reverse=True):
                self.nodeTypeData[analyticDir].append( nodeType )
                self.nodeTypeCounts[analyticDir][nodeType] = count
                self.nodeTypeCountTotals[nodeType] = self.nodeTypeCountTotals.get(nodeType, 0) + count
                self.nodeTypeTotals[analyticDir] += count
                self.nodeTypeAppearances[nodeType] = self.nodeTypeAppearances.get(nodeType,0) + 1

    #======================================================================
    #
    def __writeDetailedSummary(self):
        """
        Generate the output file containing a list of all of the node types
        and their counts.
        """
        with open(os.path.join(self.rootDir,DETAILED_FILENAME), 'wb') as csvfile:
            summaryWriter = csv.writer(csvfile, delimiter=',', quotechar='"', quoting=csv.QUOTE_MINIMAL)
            # First write out the canonical headers with the file name appearing above the
            # actual headers so that the data can be easily recognized.
            # The "sum" trick is to easily flatten out the list of lists we'd
            # otherwise get from the list comprehension. The idea is that the file
            # names appear every third column since we want them to be main headers
            # over the three columns from each file (blank, node type, count)
            summaryWriter.writerow( sum([['',j.replace(self.rootDir+'/',''),''] for j in self.directoriesToSummarize],[]) )
            summaryWriter.writerow( sum([['','Node Type','Count'] for j in self.directoriesToSummarize],[]) )
            for row in range(0,self.maxRowCount):
                rowList = []
                for analyticDir in self.directoriesToSummarize:
                    if len(self.nodeTypeData[analyticDir]) > row:
                        nodeType = self.nodeTypeData[analyticDir][row]
                        rowList += ['',nodeType,self.nodeTypeCounts[analyticDir][nodeType]]
                    else:
                        rowList += ['','','']
                summaryWriter.writerow( rowList )

    #======================================================================
    #
    def __writeCountSummary(self):
        """
        Generate the output file containing a list of all of the node type
        counts with sorting options.
        """
        appearanceColumns = [(j,k,self.nodeTypeCountTotals[j]) for j,k in self.nodeTypeAppearances.iteritems()]
        sortedAppearances = [j for j,k,_ in sorted(appearanceColumns, key=operator.itemgetter(1,2), reverse=True)]

        sortedCounts = [j for j,k in sorted(self.nodeTypeCountTotals.iteritems(), key=operator.itemgetter(1), reverse=True)]
        with open(os.path.join(self.rootDir,SUMMARY_FILENAME), 'wb') as csvfile:
            summaryWriter = csv.writer(csvfile, delimiter=',', quotechar='"', quoting=csv.QUOTE_MINIMAL)
            summaryWriter.writerow( ['Sorted By Node Type Count'
                                    ,''
                                    ,''
                                    ,'Sorted By Appearance'
                                    ,''
                                    ,''
                                    ,''
                                    ,''
                                    ,'Sorted By Node Type'] )
            summaryWriter.writerow( ['Node Type'
                                    ,'Count'
                                    , ''
                                    , 'Node Type'
                                    , 'Appearances'
                                    , 'Count'
                                    , 'Average'
                                    , ''
                                    , 'Node Type'
                                    ,'Totals'] + self.directoriesToSummarize )
            totalsRow = ['','','','','','','','','Total',sum(self.nodeTypeCountTotals.values())]
            for analyticDir in self.directoriesToSummarize:
                totalsRow += [sum(self.nodeTypeCounts[analyticDir].values())]
            summaryWriter.writerow( totalsRow )
            index = 0
            for nodeType,_ in sorted(self.nodeTypeAppearances.iteritems()):
                sortedIndex = sortedAppearances[index]
                average = 0
                if self.nodeTypeAppearances[sortedIndex] > 0:
                    average = self.nodeTypeCountTotals[sortedIndex] / self.nodeTypeAppearances[sortedIndex]
                columns = [sortedCounts[index]
                          ,self.nodeTypeCountTotals[sortedCounts[index]]
                          ,''
                          ,sortedIndex
                          ,self.nodeTypeAppearances[sortedIndex]
                          ,self.nodeTypeCountTotals[sortedIndex]
                          ,average
                          ,''
                          ,nodeType
                          ,self.nodeTypeCountTotals[nodeType]]
                for analyticDir in self.directoriesToSummarize:
                    if nodeType in self.nodeTypeData[analyticDir]:
                        columns += [self.nodeTypeCounts[analyticDir][nodeType]]
                    else:
                        columns += ['']
                summaryWriter.writerow( columns )
                index += 1

    #======================================================================
    #
    def createSummary(self):
        """
        Main working method.
            Gather the list of default nodes for exclusion.
            Read all of the analytic results from the files in the specified directory.
            Report the summarized results
        """
        self.__readDefaultNodes()
        self.__findAnalyticDirectories()
        self.__readAnalyticResults()
        self.__writeDetailedSummary()
        self.__writeCountSummary()

#======================================================================
#
# MAINLINE
#
#======================================================================

HELP_INFO = """
Usage: summarizeAnalyticNodeTypes.py [options] [rootDirectoryWithData]
       -h/--help    : Show this usage information
       -v/--verbose : Print details about how the analysis is progressing
       If no root directory is specified then use the current directory.
"""
ROOT_DIR = '.'
IS_VERBOSE = False

try:
    OPTS, ARGS = getopt.getopt(sys.argv[1:], "hv", ["help", "verbose"])
    if len(ARGS) > 0:
        ROOT_DIR = ARGS[0]
    for opt, _ in OPTS:
        if opt in ("-h", "--help"):
            print HELP_INFO
            sys.exit()
        if opt in ("-v", "--verbose"):
            IS_VERBOSE = True
except getopt.GetoptError as err:
    print str(err) # will print something like "option -a not recognized"
    print HELP_INFO
    sys.exit(2)

SUMMARY = NodeTypeSummary(ROOT_DIR)
SUMMARY.verbose = IS_VERBOSE
SUMMARY.createSummary()

# ===========================================================================
# Copyright 2016 Autodesk, Inc. All rights reserved.
#
# Use of this software is subject to the terms of the Autodesk license
# agreement provided at the time of installation or download, or which
# otherwise accompanies this software in either electronic or hard copy form.
# ===========================================================================
